{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NVffbMDdAXt",
        "outputId": "48fb8689-cedf-46cf-db7d-e10b9b94bbc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/203.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/203.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.3/299.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.0/116.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Pip install necessary package\n",
        "%pip install --upgrade --quiet  neo4j\n",
        "%pip install --upgrade --quiet  langchain-openai\n",
        "%pip install --upgrade --quiet  tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We want to use OpenAIEmbeddings so we have to get the OpenAI API Key.\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "id": "_zJgARuleZSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.docstore.document import Document\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "O5qNCVLBenX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader(\"../../modules/state_of_the_union.txt\")\n",
        "\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "MgMHh90NetFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neo4jVector requires the Neo4j database credentials\n",
        "\n",
        "url = \"bolt://localhost:7687\"\n",
        "username = \"neo4j\"\n",
        "password = \"password\"\n",
        "\n",
        "# You can also use environment variables instead of directly passing named parameters\n",
        "# os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
        "# os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
        "# os.environ[\"NEO4J_PASSWORD\"] = \"pleaseletmein\""
      ],
      "metadata": {
        "id": "RUUSnT9HetJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Similarity Search with Cosine Distance (Default)"
      ],
      "metadata": {
        "id": "MdMfGveBetMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Neo4jVector Module will connect to Neo4j and create a vector index if needed.\n",
        "\n",
        "db = Neo4jVector.from_documents(\n",
        "    docs, OpenAIEmbeddings(), url=url, username=username, password=password\n",
        ")"
      ],
      "metadata": {
        "id": "p1prqFbxetPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "docs_with_score = db.similarity_search_with_score(query, k=2)"
      ],
      "metadata": {
        "id": "3FWX-PMbetSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc, score in docs_with_score:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Score: \", score)\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "unFZbQxzetUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Working with vectorstore\n",
        "# Above, we created a vectorstore from scratch. However, often times we want to work with an existing vectorstore. In order to do that, we can initialize it directly."
      ],
      "metadata": {
        "id": "Jf2cGS57fIsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"vector\"  # default index name\n",
        "\n",
        "store = Neo4jVector.from_existing_index(\n",
        "    OpenAIEmbeddings(),\n",
        "    url=url,\n",
        "    username=username,\n",
        "    password=password,\n",
        "    index_name=index_name,\n",
        ")"
      ],
      "metadata": {
        "id": "HpIfIKjXfIwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also initialize a vectorstore from existing graph using the from_existing_graph method. This method pulls relevant text information from the database, and calculates and stores the text embeddings back to the database."
      ],
      "metadata": {
        "id": "ama0_t4cfIzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First we create sample data in graph\n",
        "store.query(\n",
        "    \"CREATE (p:Person {name: 'Tomaz', location:'Slovenia', hobby:'Bicycle', age: 33})\"\n",
        ")"
      ],
      "metadata": {
        "id": "Q2mkmYg9fI1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we initialize from existing graph\n",
        "existing_graph = Neo4jVector.from_existing_graph(\n",
        "    embedding=OpenAIEmbeddings(),\n",
        "    url=url,\n",
        "    username=username,\n",
        "    password=password,\n",
        "    index_name=\"person_index\",\n",
        "    node_label=\"Person\",\n",
        "    text_node_properties=[\"name\", \"location\"],\n",
        "    embedding_node_property=\"embedding\",\n",
        ")\n",
        "result = existing_graph.similarity_search(\"Slovenia\", k=1)"
      ],
      "metadata": {
        "id": "h3eNJRQbfI4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metadata filtering\n",
        "# Neo4j vector store also supports metadata filtering by combining parallel runtime and exact nearest neighbor search. Requires Neo4j 5.18 or greater version.\n",
        "\n",
        "# Equality filtering has the following syntax."
      ],
      "metadata": {
        "id": "LIIFm3H7fgEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "existing_graph.similarity_search(\n",
        "    \"Slovenia\",\n",
        "    filter={\"hobby\": \"Bicycle\", \"name\": \"Tomaz\"},\n",
        ")"
      ],
      "metadata": {
        "id": "xB216xJ0fgHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metadata filtering also support the following operators:\n",
        "\n",
        "# $eq: Equal\n",
        "# $ne: Not Equal\n",
        "# $lt: Less than\n",
        "# $lte: Less than or equal\n",
        "# $gt: Greater than\n",
        "# $gte: Greater than or equal\n",
        "# $in: In a list of values\n",
        "# $nin: Not in a list of values\n",
        "# $between: Between two values\n",
        "# $like: Text contains value\n",
        "# $ilike: lowered text contains value"
      ],
      "metadata": {
        "id": "Nm9qGajWfgKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "existing_graph.similarity_search(\n",
        "    \"Slovenia\",\n",
        "    filter={\"hobby\": {\"$eq\": \"Bicycle\"}, \"age\": {\"$gt\": 15}},\n",
        ")"
      ],
      "metadata": {
        "id": "_y60g_K-fgM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "existing_graph.similarity_search(\n",
        "    \"Slovenia\",\n",
        "    filter={\"hobby\": {\"$eq\": \"Bicycle\"}, \"age\": {\"$gt\": 15}},\n",
        ")"
      ],
      "metadata": {
        "id": "b7UxzM8mfgPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "existing_graph.similarity_search(\n",
        "    \"Slovenia\",\n",
        "    filter={\"$or\": [{\"hobby\": {\"$eq\": \"Bicycle\"}}, {\"age\": {\"$gt\": 15}}]},\n",
        ")"
      ],
      "metadata": {
        "id": "wE7SEDuBfgSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add documents\n",
        "# We can add documents to the existing vectorstore."
      ],
      "metadata": {
        "id": "8eU3I61VfgVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store.add_documents([Document(page_content=\"foo\")])"
      ],
      "metadata": {
        "id": "EraCyvlaf76Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_with_score = store.similarity_search_with_score(\"foo\")"
      ],
      "metadata": {
        "id": "gv5FNJN-f79W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Customize response with retrieval query\n",
        "# You can also customize responses by using a custom Cypher snippet that can fetch other information from the graph. Under the hood, the final Cypher statement is constructed like so:\n",
        "\n"
      ],
      "metadata": {
        "id": "RhyGp4IQf8Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "read_query = (\n",
        "  \"CALL db.index.vector.queryNodes($index, $k, $embedding) \"\n",
        "  \"YIELD node, score \"\n",
        ") + retrieval_query"
      ],
      "metadata": {
        "id": "gKuHepg_f8Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The retrieval query must return the following three columns:\n",
        "\n",
        "# text: Union[str, Dict] = Value used to populate page_content of a document\n",
        "# score: Float = Similarity score\n",
        "# # metadata: Dict = Additional metadata of a document"
      ],
      "metadata": {
        "id": "wb7yWyu6gJ9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval_query = \"\"\"\n",
        "RETURN \"Name:\" + node.name AS text, score, {foo:\"bar\"} AS metadata\n",
        "\"\"\"\n",
        "retrieval_example = Neo4jVector.from_existing_index(\n",
        "    OpenAIEmbeddings(),\n",
        "    url=url,\n",
        "    username=username,\n",
        "    password=password,\n",
        "    index_name=\"person_index\",\n",
        "    retrieval_query=retrieval_query,\n",
        ")\n",
        "retrieval_example.similarity_search(\"Foo\", k=1)"
      ],
      "metadata": {
        "id": "PSz7lmnSgKBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval_query = \"\"\"\n",
        "RETURN node {.name, .age, .hobby} AS text, score, {foo:\"bar\"} AS metadata\n",
        "\"\"\"\n",
        "retrieval_example = Neo4jVector.from_existing_index(\n",
        "    OpenAIEmbeddings(),\n",
        "    url=url,\n",
        "    username=username,\n",
        "    password=password,\n",
        "    index_name=\"person_index\",\n",
        "    retrieval_query=retrieval_query,\n",
        ")\n",
        "retrieval_example.similarity_search(\"Foo\", k=1)"
      ],
      "metadata": {
        "id": "tf3d8cj5gKDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval_query = \"\"\"\n",
        "RETURN node {.*, embedding:Null, extra: $extra} AS text, score, {foo:\"bar\"} AS metadata\n",
        "\"\"\"\n",
        "retrieval_example = Neo4jVector.from_existing_index(\n",
        "    OpenAIEmbeddings(),\n",
        "    url=url,\n",
        "    username=username,\n",
        "    password=password,\n",
        "    index_name=\"person_index\",\n",
        "    retrieval_query=retrieval_query,\n",
        ")\n",
        "retrieval_example.similarity_search(\"Foo\", k=1, params={\"extra\": \"ParamInfo\"})"
      ],
      "metadata": {
        "id": "4E16Xc1IgKJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hybrid search (vector + keyword)\n",
        "# Neo4j integrates both vector and keyword indexes, which allows you to use a hybrid search approach"
      ],
      "metadata": {
        "id": "exsxt5jQgKMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Neo4jVector Module will connect to Neo4j and create a vector and keyword indices if needed.\n",
        "hybrid_db = Neo4jVector.from_documents(\n",
        "    docs,\n",
        "    OpenAIEmbeddings(),\n",
        "    url=url,\n",
        "    username=username,\n",
        "    password=password,\n",
        "    search_type=\"hybrid\",\n",
        ")"
      ],
      "metadata": {
        "id": "k2o8iiRwgg9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"vector\"  # default index name\n",
        "keyword_index_name = \"keyword\"  # default keyword index name\n",
        "\n",
        "store = Neo4jVector.from_existing_index(\n",
        "    OpenAIEmbeddings(),\n",
        "    url=url,\n",
        "    username=username,\n",
        "    password=password,\n",
        "    index_name=index_name,\n",
        "    keyword_index_name=keyword_index_name,\n",
        "    search_type=\"hybrid\",\n",
        ")"
      ],
      "metadata": {
        "id": "DMwX8CIOgvC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retriever options\n",
        "# This section shows how to use Neo4jVector as a retriever.\n"
      ],
      "metadata": {
        "id": "YvpB70bVgvGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = store.as_retriever()\n",
        "retriever.invoke(query)[0]"
      ],
      "metadata": {
        "id": "2JY4hguAgvJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question Answering with Sources\n",
        "# This section goes over how to do question-answering with sources over an Index. It does this by using the RetrievalQAWithSourcesChain, which does the lookup of the documents from an Index."
      ],
      "metadata": {
        "id": "NVZ6Imj2gvMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "VN-XnE1PgvPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    ChatOpenAI(temperature=0), chain_type=\"stuff\", retriever=retriever\n",
        ")"
      ],
      "metadata": {
        "id": "QQK4uMhughBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GVlO-tehghEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cgiyhvNYghGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YhneqpF4ghJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NG_UL_kcghMd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}